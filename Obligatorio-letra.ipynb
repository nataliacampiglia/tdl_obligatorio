{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obligatorio - Taller de Deep Learning\n",
    "\n",
    "**Fecha de entrega:** 3/12/2025  \n",
    "**Puntaje máximo:** 50 puntos\n",
    "\n",
    "**Alumno(s):** [Nombre(s) y Apellido(s)]\n",
    "\n",
    "## Obligatorio\n",
    "\n",
    "El objetivo de este obligatorio es evaluar su conocimiento en Deep Learning mediante la implementación completa de un modelo de segmentación de imágenes basado en el paper [**\"U-Net: Convolutional Networks for Biomedical Image Segmentation\"**](https://arxiv.org/pdf/1505.04597). Toda la implementación debe realizarse desde cero utilizando PyTorch, y los estudiantes tendrán la libertad de ajustar ciertos hiperparámetros y configuraciones mientras mantengan la esencia del paper original.\n",
    "\n",
    "### **Competencia en Kaggle**\n",
    "\n",
    "Además, como parte de este obligatorio, participarán en una competencia privada en Kaggle donde se les proporcionará un dataset de test oculto (sin target). Deberán subir sus predicciones a Kaggle y se evaluarán en función de la métrica **Dice Coefficient (Coeficiente de Dice)**. Esta competencia les permitirá comparar sus resultados con los de sus compañeros en un entorno real de evaluación.\n",
    "\n",
    "### **¿Qué es el Dice Coefficient?**\n",
    "El **Dice Coefficient**, también conocido como F1-score para segmentación, es una métrica utilizada para evaluar la similitud entre la predicción y la verdad del terreno en tareas de segmentación. Se define de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\text{Dice} = \\frac{2 \\cdot |A \\cap B|}{|A| + |B|}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $A$ es el conjunto de píxeles predichos como pertenecientes a la clase positiva.\n",
    "- $B$ es el conjunto de píxeles verdaderos pertenecientes a la clase positiva.\n",
    "- $|A \\cap B|$ es la intersección de $A$ y $B$, es decir, los píxeles correctamente predichos como positivos.\n",
    "\n",
    "Un valor de Dice de **1** indica una predicción perfecta, mientras que un valor de **0** indica que no hay coincidencia entre la predicción y el valor verdadero. Durante la competencia de Kaggle, deberán obtener un puntaje de al menos **0.75** en la métrica Dice para considerarse aprobados.\n",
    "\n",
    "### **Criterios a Evaluar**\n",
    "\n",
    "1. **Análisis del Dataset (5 puntos):**\n",
    "   - Exploración y visualización del dataset para comprender su estructura y características.\n",
    "   - Justificación de las decisiones tomadas en la preprocesamiento de datos, como normalización, aumento de datos (data augmentation), y partición del dataset en conjuntos de entrenamiento, validación y prueba.\n",
    "\n",
    "2. **Implementación Correcta del Modelo U-Net (20 puntos):**\n",
    "   - Construcción de la arquitectura U-Net siguiendo la estructura descrita en el paper, permitiendo ajustes como el número de filtros, funciones de activación y métodos de inicialización de pesos.\n",
    "   - Se aceptan mejoras como el uso de técnicas adicionales como batch normalization, otras funciones de activación, etc.\n",
    "\n",
    "3. **Entrenamiento del Modelo (10 puntos):**\n",
    "   - Configuración adecuada del ciclo de entrenamiento, incluyendo la elección de la función de pérdida y del optimizador (Adam, SGD, etc.).\n",
    "   - Uso de técnicas de regularización para mejorar la generalización del modelo, como el dropout, normalización de batch y data augmentation.\n",
    "   - Gráficas y análisis de la evolución del entrenamiento, mostrando las curvas de pérdida y métricas relevantes tanto en el conjunto de entrenamiento como en el de validación.\n",
    "   - Puede utilizarse experimentación con hiperparámetros con Weights & Biases (W&B) para optimizar el rendimiento del modelo. Este punto no es obligatorio, pero se valorará positivamente si se justifica su uso y se presentan resultados claros.\n",
    "\n",
    "4. **Evaluación de Resultados (10 puntos):**\n",
    "   - Evaluación exhaustiva del modelo utilizando métricas de segmentación como **Dice Coefficient**.\n",
    "   - Análisis detallado de los resultados, incluyendo un análisis de errores para identificar y discutir casos difíciles.\n",
    "   - Visualización de ejemplos representativos de segmentaciones correctas e incorrectas, comparando con las etiquetas manuales proporcionadas en el dataset.\n",
    "\n",
    "5. **Participación y Resultados en la Competencia Kaggle (5 puntos):**\n",
    "   - Participación activa en la competencia de Kaggle, con al menos una (1) subida de predicción.\n",
    "   - Puntaje obtenido en la tabla de posiciones de Kaggle, evaluado en base al **Dice Coefficient** en el conjunto de test oculto. Es necesario obtener al menos un valor de **0.75** para esta métrica.\n",
    "\n",
    "   Notas: \n",
    "   - **Cualquier decisión debe ser justificada en el notebook.**\n",
    "   - El **Dice Coefficient** es la métrica utilizada para evaluar la precisión de los modelos de segmentación de imágenes en esta competencia.\n",
    "\n",
    "### **Run-Length Encoding (RLE)**\n",
    "\n",
    "Dado que no se suben las imágenes segmentadas directamente a Kaggle, se requiere usar **Run-Length Encoding (RLE)** para comprimir las máscaras de predicción en una cadena de texto que será evaluada. El **RLE** es una técnica de compresión donde se representan secuencias consecutivas de píxeles en formato `start length`, indicando la posición de inicio y la longitud de cada secuencia de píxeles positivos.\n",
    "\n",
    "Para calcular el **RLE**, se sigue el siguiente proceso:\n",
    "\n",
    "1. Se aplanan las máscaras predichas en un solo vector\n",
    "2. Se identifican los píxeles con valor positivo (1) y se calculan las secuencias consecutivas.\n",
    "3. Se registra la posición de inicio de cada secuencia y su longitud en formato `start length`.\n",
    "\n",
    "Este formato comprimido se sube a Kaggle en lugar de las imágenes segmentadas.\n",
    "\n",
    "#### **Ejemplo de RLE**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def rle_encode(mask):\n",
    "    pixels = np.array(mask).flatten(order='F')  # Aplanar la máscara en orden Fortran\n",
    "    pixels = np.concatenate([[0], pixels, [0]])  # Añadir ceros al principio y final\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1  # Encontrar transiciones\n",
    "    runs[1::2] = runs[1::2] - runs[::2]  # Calcular longitudes\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "mask = np.array([[0, 0, 1, 0, 0],\n",
    "                 [0, 1, 1, 1, 0],\n",
    "                 [1, 1, 1, 0, 0],\n",
    "                 [0, 0, 0, 1, 1]])\n",
    "\n",
    "print(rle_encode(mask))\n",
    "```\n",
    "\n",
    "> **Salida:** 3 1 6 2 9 3 14 1 16 1 20 1\n",
    "\n",
    "\n",
    "### **Sobre el Dataset**\n",
    "\n",
    "El dataset proporcionado para esta tarea incluirá imágenes y máscaras para la segmentación de un conjunto específico de clases. El conjunto de entrenamiento estará disponible para su uso durante todo el proceso de desarrollo y pruebas, mientras que el conjunto de validación se mantendrá oculto para la evaluación final en Kaggle.\n",
    "\n",
    "### **Instrucciones de Entrega**\n",
    "\n",
    "- Deberán entregar un Jupyter Notebook (.ipynb) que contenga todo el código y las explicaciones necesarias para ejecutar la implementación, el entrenamiento y la evaluación del modelo.\n",
    "- El notebook debe incluir secciones bien documentadas explicando las decisiones de diseño del modelo, los experimentos realizados, y los resultados obtenidos.\n",
    "- El código debe estar escrito de manera clara.\n",
    "- La entrega debe realizarse a través de la plataforma de gestión de ORT (gestion.ort.edu.uy) antes de la fecha límite.\n",
    "\n",
    "### **Materiales Adicionales**\n",
    "\n",
    "Para facilitar su trabajo, pueden consultar los siguientes recursos:\n",
    "\n",
    "- [U-Net: Convolutional Networks for Biomedical Image Segmentation (paper original)](https://arxiv.org/abs/1505.04597)\n",
    "- [Documentación de PyTorch](https://pytorch.org/docs/stable/index.html)\n",
    "- [Tutoriales y recursos adicionales en Kaggle](https://www.kaggle.com/)\n",
    "- [Convolución Transpuesta](https://d2l.ai/chapter_computer-vision/transposed-conv.html)\n",
    "\n",
    "### **Competencia Kaggle**\n",
    "\n",
    "[Link a la competencia Kaggle](https://www.kaggle.com/competitions/tdl-obligatorio-2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
